interactions:
- request:
    body: grant_type=%5B%27refresh_token%27%5D&client_id=%5B%27764086051850-6qr4p6gpi6hn506pt8ejuq83di341hur.apps.googleusercontent.com%27%5D&client_secret=%5B%27scrubbed%27%5D&refresh_token=%5B%271%2F%2F0hJpJJHIB_6HFCgYIARAAGBESNwF-L9IrkG8wcCCqUWVHIGwfOv00CBx1kTldn70NgzEsmDiAXdhl11ROL_myqR5Tp524g4JVp_Q%27%5D
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      content-length:
      - '268'
      content-type:
      - application/x-www-form-urlencoded
    method: POST
    uri: https://oauth2.googleapis.com/token
  response:
    headers:
      alt-svc:
      - h3=":443"; ma=2592000,h3-29=":443"; ma=2592000
      cache-control:
      - no-cache, no-store, max-age=0, must-revalidate
      content-length:
      - '1419'
      content-type:
      - application/json; charset=utf-8
      expires:
      - Mon, 01 Jan 1990 00:00:00 GMT
      pragma:
      - no-cache
      transfer-encoding:
      - chunked
      vary:
      - Origin
      - X-Origin
      - Referer
    parsed_body:
      access_token: scrubbed
      expires_in: 3599
      id_token: eyJhbGciOiJSUzI1NiIsImtpZCI6IjI1ZjgyMTE3MTM3ODhiNjE0NTQ3NGI1MDI5YjAxNDFiZDViM2RlOWMiLCJ0eXAiOiJKV1QifQ.eyJpc3MiOiJodHRwczovL2FjY291bnRzLmdvb2dsZS5jb20iLCJhenAiOiI3NjQwODYwNTE4NTAtNnFyNHA2Z3BpNmhuNTA2cHQ4ZWp1cTgzZGkzNDFodXIuYXBwcy5nb29nbGV1c2VyY29udGVudC5jb20iLCJhdWQiOiI3NjQwODYwNTE4NTAtNnFyNHA2Z3BpNmhuNTA2cHQ4ZWp1cTgzZGkzNDFodXIuYXBwcy5nb29nbGV1c2VyY29udGVudC5jb20iLCJzdWIiOiIxMDY1Njg0NzQzMTU3NzkyMTI1NTkiLCJoZCI6InB5ZGFudGljLmRldiIsImVtYWlsIjoibWFyY2Vsb0BweWRhbnRpYy5kZXYiLCJlbWFpbF92ZXJpZmllZCI6dHJ1ZSwiYXRfaGFzaCI6ImxXS3ktMWJoSm4zc1dJX3JGWDR0SXciLCJpYXQiOjE3NDE2MDEwODEsImV4cCI6MTc0MTYwNDY4MX0.ruiOxbn4jFxpCzYBGBtfU7q1k4VMHoXpY6jGQ2-TT12Uwqm3dolE8vtzAIKYmDA2D0ZdeL0Dpk0_oX4-yBwiGMISAFK8wtB0wU2yB4ChOoSjrXf8hmT57GoVHexnKnGZhV0plqkFqAKwmvpdM3t0EKnGA8brYHj7HClBjhaj4N-LJzxpvzoimFo1T-yo6PGyebSbuVr3SP2_lKXf0OSOzBNpTabzZ5xb-yVHCXQeowZ0GpYp5NGGmyCKQlhNeVObWuH8cF8fah1AfAJoFw7sViKUQOqAStiBWQj8sFQh8QPPhzHAF7D9vLNjpqzFizGzBCcqdhvOh8WK7z5F_vpSdw
      scope: https://www.googleapis.com/auth/sqlservice.login openid https://www.googleapis.com/auth/cloud-platform https://www.googleapis.com/auth/userinfo.email
      token_type: Bearer
    status:
      code: 200
      message: OK
- request:
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      content-length:
      - '207'
      content-type:
      - application/json
      host:
      - us-central1-aiplatform.googleapis.com
    method: POST
    parsed_body:
      contents:
      - parts:
        - text: What is the main content on this document?
        - fileData:
            fileUri: gs://cloud-samples-data/generative-ai/pdf/2403.05530.pdf
            mimeType: application/pdf
        role: user
    uri: https://us-central1-aiplatform.googleapis.com/v1/projects/pydantic-platform/locations/us-central1/publishers/google/models/gemini-2.0-flash-thinking-exp-01-21:generateContent
  response:
    headers:
      alt-svc:
      - h3=":443"; ma=2592000,h3-29=":443"; ma=2592000
      content-length:
      - '2519'
      content-type:
      - application/json; charset=UTF-8
      transfer-encoding:
      - chunked
      vary:
      - Origin
      - X-Origin
      - Referer
    parsed_body:
      candidates:
      - content:
          parts:
          - text: |-
              The main content of this document is the **introduction of Gemini 1.5 Pro**, a new multimodal language model from Google DeepMind.

              Key highlights from the document are:

              *   **Gemini 1.5 Pro is a highly compute-efficient multimodal mixture-of-experts model.**
              *   **Unlocking multimodal understanding across millions of tokens of context:**  It can process significantly longer context windows than previous models (up to 10M tokens), enabling it to reason over massive amounts of text, audio, and video.
              *   **Near-perfect recall and improved performance:** It achieves near-perfect recall on long-context retrieval tasks and improves the state-of-the-art in long-document QA, long-video QA, and long-context ASR. It matches or surpasses the performance of Gemini 1.0 Ultra in various benchmarks.
              *   **Surprising new capabilities:**  The model demonstrates remarkable in-context learning abilities, such as learning to translate a new language (Kalamang) from a grammar manual provided as context, achieving translation quality comparable to a human learner using the same material.
              *   **Detailed evaluations:** The document provides extensive evaluations of Gemini 1.5 Pro's long-context capabilities and core multimodal abilities, comparing it to Gemini 1.0 family models and other leading models like Claude 2.1 and GPT-4 Turbo.
              *   **Discussion of responsible deployment:**  The document briefly mentions Google's approach to responsible deployment, including impact assessment and safety evaluations.

              In essence, the document announces Gemini 1.5 Pro as a significant advancement in multimodal AI, particularly in its ability to handle extremely long contexts and demonstrate strong reasoning and learning capabilities across various modalities.
          role: model
        finishReason: STOP
      createTime: '2025-03-10T10:04:41.865260Z'
      modelVersion: gemini-2.0-flash-thinking-exp-01-21
      responseId: ObnOZ-znNI2TmecP05GV8AE
      usageMetadata:
        candidatesTokenCount: 358
        candidatesTokensDetails:
        - modality: TEXT
          tokenCount: 358
        promptTokenCount: 19875
        promptTokensDetails:
        - modality: TEXT
          tokenCount: 9
        - modality: DOCUMENT
          tokenCount: 19866
        totalTokenCount: 20233
    status:
      code: 200
      message: OK
version: 1
